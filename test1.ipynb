{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VyjoMJdHeDX",
        "outputId": "dbd9b582-5938-49a3-ab10-e96b80fb407d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10015 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#!pip install opencv-python\n",
        "#!pip install -q tf-focal-frequency-loss\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "import pathlib\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tf_focal_frequency_loss import FocalFrequencyLoss as FFL\n",
        "\n",
        "#!rm -r ~/.kaggle\n",
        "#!mkdir ~/.kaggle\n",
        "#!mv ./kaggle.json ~/.kaggle/\n",
        "#!chmod 600 ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000\n",
        "\n",
        "#!unzip /content/skin-cancer-mnist-ham10000.zip\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(256, input_shape=(100,), use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Dense(512, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Dense(12288, activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def generate_images(model, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow((predictions[i, :, :] + 1) / 2.0)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "image_size = (64, 64)\n",
        "batch_size = 256\n",
        "data_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
        "train_dataset = data_generator.flow_from_directory(\n",
        "    '/content/Images',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "num_images = 100\n",
        "selected_images = []\n",
        "for i in range(num_images):\n",
        "    selected_images.append(next(train_dataset))\n",
        "selected_images = np.concatenate(selected_images, axis=0)\n",
        "selected_images = selected_images[:num_images]\n",
        "\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            generate_images(generator, tf.random.normal([16, 100]))\n",
        "\n",
        "EPOCHS = 100\n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuU9m3qF8FJyzU9c/lPuCz"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
